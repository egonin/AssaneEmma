{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337b2466",
   "metadata": {},
   "source": [
    "# Avant de run le code, il est nécessaire d'installer deeplake avec \"pip install deeplake\" via le terminal de commande.\n",
    "Cette librairie nous permet d'utiliser une base de données EMNIST, constituée de caractères de toute sorte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7eda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow\n",
    "import matplotlib.pyplot\n",
    "import deeplake\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "SGD = tensorflow.keras.optimizers.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c401d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/emnist-byclass-train loaded successfully.\n",
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/emnist-byclass-train\n",
      "hub://activeloop/emnist-byclass-test loaded successfully.\n",
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/emnist-byclass-test\n"
     ]
    }
   ],
   "source": [
    "ds_train = deeplake.load(\"hub://activeloop/emnist-byclass-train\")\n",
    "ds_test = deeplake.load(\"hub://activeloop/emnist-byclass-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad03c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(697932, 28, 28)\n",
      "Les dimensions d'une image de la base de données sont :  (28, 28)\n",
      "Le nombre d'images dans la base de données est :  697932\n"
     ]
    }
   ],
   "source": [
    "X_train=ds_train.images\n",
    "Y_train=ds_train.labels\n",
    "print(X_train.shape)\n",
    "print(\"Les dimensions d'une image de la base de données sont : \", X_train[2].shape)\n",
    "print(\"Le nombre d'images dans la base de données est : \", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1319faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=ds_test.images\n",
    "Y_test=ds_test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa9b6394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23435d1d490>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.pyplot.imshow(X_test[2].numpy(), cmap=matplotlib.pyplot.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7de2b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici la représentation numpy de la 5e image du dataset d'entrainement [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "   32  82 127 127 127 127 170 138  18   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   4  46 125 141\n",
      "  243 252 254 254 253 250 245 202  20   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   4  21  82 129 204 246 254 251\n",
      "  222 215 140 127 114  39  32   4   0   0]\n",
      " [  0   0   0   0   4   5  21  50 125 140 215 233 252 253 245 204 129  82\n",
      "    9   4   0   0   0   0   0   0   0   0]\n",
      " [  0   5  50 139 215 217 233 250 254 254 250 232 140 114  34   4   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  37 246 254 254 255 254 220 140 125  50  21   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  32 229 250 250 252 253 125  35   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  21  37  37  82 188 253 243 141  77   1   2   2   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  20 125 172 246 245 141 172 108   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2  36 211 253 251 251  65   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   4 158 234 251 163  54 218 201   4   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1  47 202 253 251 131   7   0  22  95   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  22 128 244 254 232  95   7   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  47 218 254 249 203  22   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  21 230 254 232 122   6   0   0   0   0   0   0   0   0   2   4   3\n",
      "    2   0   0   0   0   0   0   0   0   0]\n",
      " [  0  37 249 211  40  22  21   4   9  37  37  37  51 125 127 172 215 185\n",
      "  172 127 114  37  37   9   2   0   0   0]\n",
      " [  0  37 249 226 217 233 233 217 221 249 250 250 250 250 250 250 250 250\n",
      "  250 250 249 245 245 217 117   0   0   0]\n",
      " [  0  32 224 217 217 215 185 215 140 129 159 127 125  51  37  37  37  37\n",
      "   37  37  37  37  37  37  30   0   0   0]\n",
      " [  0   1  16   4   4   4   3   4   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2343ad67160>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_arr = X_train[4]\n",
    "print(\"Voici la représentation numpy de la 5e image du dataset d'entrainement\", image_arr.numpy())\n",
    "\n",
    "matplotlib.pyplot.imshow(image_arr, cmap=matplotlib.pyplot.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f3f40",
   "metadata": {},
   "source": [
    "Transforme les matrices 28x28 en vecteur de 784 lignes (cellule longue à charger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f11e6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train\u001b[38;5;241m=\u001b[39m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m()\n\u001b[0;32m      2\u001b[0m X_train\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mreshape(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m784\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "X_train=X_train.numpy()\n",
    "X_train=X_train.reshape(X_train.shape[0],784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07f767a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.numpy()\n",
    "X_test=X_test.reshape(X_test.shape[0],784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5af52d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(697932, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24d23f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116323, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a3948",
   "metadata": {},
   "source": [
    "Normalise les vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "771353fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =(X_train.astype('int32')-127.5)/127.5\n",
    "X_test  = (X_test.astype('int32')-127.5)/127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49254b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_entree = 784\n",
    "nbneurones1 = 250\n",
    "nbneurones2 = 128\n",
    "nbneurones3 = 62\n",
    "nbneurones4 = 10\n",
    "epoch = 50\n",
    "batchsize = 250\n",
    "taux_apprentissage = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6b67f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 250)               196250    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32128     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 62)                7998      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 62)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                630       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 237,006\n",
      "Trainable params: 237,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Modèle de réseau de neurones avec 3 couches\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(nbneurones1, input_shape=(dimension_entree,)))  \n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(nbneurones2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(nbneurones3))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(nbneurones4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f76eb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des hyperparamètres de l'entraînement\n",
    "sgd = SGD(lr=taux_apprentissage)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='sgd', \n",
    "    metrics=['accuracy']  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffe2cd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.04 GiB for an array with shape (697932, 784) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Entraînement\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hist_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1049\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1043\u001b[0m   val_x, val_y, val_sample_weight \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1044\u001b[0m       data_adapter\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(validation_data))\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[0;32m   1047\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1048\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1049\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1065\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1105\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1104\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1119\u001b[0m strategy \u001b[38;5;241m=\u001b[39m ds_context\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1120\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter\u001b[38;5;241m.\u001b[39mget_dataset()\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:476\u001b[0m, in \u001b[0;36mGenericArrayLikeDataAdapter.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    470\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    471\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras is training/fitting/evaluating on array-like data. Keras may \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    472\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be optimized for this format, so if your input data format is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    473\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by TensorFlow I/O (https://github.com/tensorflow/io) we \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    474\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecommend using that to load a Dataset instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 476\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGenericArrayLikeDataAdapter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:265\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    255\u001b[0m              x,\n\u001b[0;32m    256\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    263\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    264\u001b[0m   \u001b[38;5;28msuper\u001b[39m(TensorLikeDataAdapter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 265\u001b[0m   x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m   sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m       sample_weights, sample_weight_modes)\n\u001b[0;32m    269\u001b[0m   \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1021\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[0;32m   1019\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m-> 1021\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_numpy_and_scipy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:635\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m [flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure]\n\u001b[0;32m    632\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 635\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    636\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:635\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    631\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m [flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure]\n\u001b[0;32m    632\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 635\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    636\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1016\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1014\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[0;32m   1015\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[1;32m-> 1016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scipy_sparse \u001b[38;5;129;01mand\u001b[39;00m scipy_sparse\u001b[38;5;241m.\u001b[39missparse(x):\n\u001b[0;32m   1018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1499\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1494\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1495\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1496\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1499\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1502\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    168\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:275\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    274\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 275\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    278\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:300\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    299\u001b[0m   \u001b[38;5;124;03m\"\"\"Implementation of eager constant.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\.conda\\envs\\projetassane\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.04 GiB for an array with shape (697932, 784) and data type float32"
     ]
    }
   ],
   "source": [
    "# Entraînement\n",
    "model_train = model.fit(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    batch_size=batchsize,\n",
    "    epochs=epoch,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601ba49",
   "metadata": {},
   "source": [
    "## La cellule suivante doit être run une seule et unique fois !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29161baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34cb7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On affiche les résultats\n",
    "\n",
    "#Courbe de loss\n",
    "\n",
    "epochs = range(1, epoch+1)\n",
    "\n",
    "loss_train = model_train.history[\"loss\"]\n",
    "accuracy_train = model_train.history[\"accuracy\"]\n",
    "\n",
    "loss_test = model_train.history[\"val_loss\"]\n",
    "accuracy_test = model_train.history[\"val_accuracy\"]\n",
    "\n",
    "#Courbe de loss\n",
    "matplotlib.pyplot.figure()\n",
    "matplotlib.pyplot.plot(epochs, loss_train, 'r+', label=\"Fonction de coût de l'entraînement\")\n",
    "matplotlib.pyplot.plot(epochs, loss_test, 'b+', label=\"Fonction de coût de test\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.xlabel(\"epochs\")\n",
    "matplotlib.pyplot.title(\"Fonction de coût\")\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "#Courbe d'accuracy (métrique qui permet de valider le modèle)\n",
    "\n",
    "matplotlib.pyplot.figure()\n",
    "matplotlib.pyplot.plot(epochs, accuracy_train, 'r+', label=\"Accuracy de l'entraînement\")\n",
    "matplotlib.pyplot.plot(epochs, accuracy_test, 'b+', label=\"Accuracy de test\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.xlabel(\"epochs\")\n",
    "matplotlib.pyplot.title(\"Accuracy\")\n",
    "matplotlib.pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
